{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Precipitation_Nowcasting",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekapolc/pattern_2019/blob/master/HW/HW4/HW4_Precipitation_Nowcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjRBQ9voFMYx",
        "colab_type": "text"
      },
      "source": [
        "# Precipitation Nowcasting using Neural Networks\n",
        "\n",
        "In this exercise, you are going to build a set of deep learning models on a real world task using Tensorflow and Keras. Tensorflow is a deep learning framwork developed by Google, and Keras is a frontend library built on top of Tensorflow (or Theano, CNTK) to provide an easier way to use standard layers and networks.\n",
        "\n",
        "## Setting up to use the gpu  \n",
        "\n",
        "Before we start, we need to change the environment of Colab to use GPU. Do so by:\n",
        "\n",
        "Runtime -> Change runtime type -> Hardware accelerator -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aelm29BaFKuc",
        "colab_type": "text"
      },
      "source": [
        "## Deep Neural Networks with Keras ##\n",
        "\n",
        "To complete this exercise, you will need to build deep learning models for precipitation nowcasting. You will build a subset of the models shown below:\n",
        "- Fully Connected (Feedforward) Neural Network\n",
        "- Two-Dimentional Convolution Neural Network (2D-CNN)\n",
        "- Recurrent Neural Network with Gated Recurrent Unit (GRU)\n",
        "\n",
        "and one more model of your choice to achieve the highest score possible.\n",
        "\n",
        "We provide the code for data cleaning and some starter code for keras in this notebook but feel free to modify those parts to suit your needs. You can also complete this exercise using only Tensorflow (without using Keras). Feel free to use additional libraries (e.g. scikit-learn) as long as you have a model for each type mentioned above.\n",
        "\n",
        "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on Colab you are all set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt5qwVJXFKue",
        "colab_type": "text"
      },
      "source": [
        "## Precipitation Nowcasting ##\n",
        "\n",
        "Precipitation nowcasting is the the task of predicting the amount of rainfall in a certain region given some kind of sensor data.  The term nowcasting refers to tasks that try to predict the current or near future conditions (within 6 hours). \n",
        "\n",
        "You will be given satellite images in 3 different bands covering a 5 by 5 region from different parts of Thailand. In other words, your input will be a 5x5x3 image. Your task is to predict the amount of rainfal in the center pixel. You will first do the prediction using just a simple fully-connected neural network that view each pixel as different input features.\n",
        "\n",
        "Since the your input is basically an image, we will then view the input as an image and apply CNN to do the prediction. Finally, we can also add a time component since weather prediction can benefit greatly using previous time frames. Each data point actually contain 5 time steps, so each input data point has a size of 5x5x5x3 (time x height x width x channel), and the output data has a size of 5 (time). You will use this time information when you work with RNNs.\n",
        "\n",
        "Finally, we would like to thank the Thai Meteorological Department for providing the data for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQFOLhM5F2k",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data\n",
        "Get the data set by going [here](https://drive.google.com/file/d/1NWR22fVVE0tO2Q5EbaPPrRKPhUem-jbw/view?usp=sharing) and click add to drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpV236cQtYvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard extension\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYYloecSFKuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYCGn6wkF4Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwSDsVaNGbKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip '/content/gdrive/My Drive/dataset.zip'\n",
        "!tar -xvf '/content/gdrive/My Drive/nowcastingHWdataset.tar.gz'\n",
        "#!tar -xvf '/content/gdrive/My Drive/pattern/pattern2018/homework/HW4/nowcastingHWdataset.tar.gz'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syY5DXvFFKuj",
        "colab_type": "text"
      },
      "source": [
        "# Data Explanation #\n",
        "\n",
        "The data is an hourly measurement of water vapor in the atmosphere, and two infrared measurements of cloud imagery on a latitude-longitude coordinate. Each measurement is illustrated below as an image. These three features are included as different channels in your input data.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/wvapor.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud1.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud2.png\" width=\"200\">\n",
        "\n",
        "We also provide the hourly precipitation (rainfall) records in the month of June, July, August, September, and October from weather stations spreaded around the country. A 5x5 grid around each weather station at a particular time will be paired with the precipitation recorded at the corresponding station as input and output data. Finally, five adjacent timesteps are stacked into one sequence.\n",
        "\n",
        "The month of June-August are provided as training data, while the months of September and October are used as validation and test sets, respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ieaQpHFKuk",
        "colab_type": "text"
      },
      "source": [
        "# Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg0gCg-DFKul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(months, data_dir='dataset'):\n",
        "    features = np.array([], dtype=np.float32).reshape(0,5,5,5,3)\n",
        "    labels = np.array([], dtype=np.float32).reshape(0,5)\n",
        "    for m in months:\n",
        "        filename = 'features-m{}.pk'.format(m)\n",
        "        with open(os.path.join(data_dir,filename), 'rb') as file:\n",
        "            features_temp = pickle.load(file)\n",
        "        features = np.concatenate((features, features_temp), axis=0)\n",
        "        \n",
        "        filename = 'labels-m{}.pk'.format(m)\n",
        "        with open(os.path.join(data_dir,filename), 'rb') as file:\n",
        "            labels_temp = pickle.load(file)\n",
        "        labels = np.concatenate((labels, labels_temp), axis=0)\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3zFs-CXFKuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use data from month 6,7,8 as training set\n",
        "x_train, y_train = read_data(months=[6,7,8])\n",
        "\n",
        "# use data from month 9 as validation set\n",
        "x_val, y_val = read_data(months=[9])\n",
        "\n",
        "# use data from month 10 as test set\n",
        "x_test, y_test = read_data(months=[10])\n",
        "\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:', y_train.shape, '\\n')\n",
        "print('x_val shape:',x_val.shape)\n",
        "print('y_val shape:', y_val.shape, '\\n')\n",
        "print('x_test shape:',x_test.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW6GD-8-FKur",
        "colab_type": "text"
      },
      "source": [
        "**features** \n",
        "- dim 0: number of entries\n",
        "- dim 1: number of time-steps in ascending order\n",
        "- dim 2,3: a 5x5 grid around rain-measued station\n",
        "- dim 4: water vapor and two cloud imagenaries \n",
        "\n",
        "**labels**\n",
        "- dim 0: number of entries\n",
        "- dim 1: number of precipitation for each time-step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCKaJISBFKus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizer_std(X):\n",
        "    scaler = preprocessing.StandardScaler().fit(X)\n",
        "    return scaler\n",
        "\n",
        "def normalizer_minmax(X):\n",
        "    scaler = preprocessing.MinMaxScaler().fit(X)\n",
        "    return scaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnNVxatKFKuy",
        "colab_type": "text"
      },
      "source": [
        "# Three-Layer Feedforward Neural Networks\n",
        "\n",
        "Below, the code for creating a 3-layers fully connected neural network in keras is provided. Run the code and make sure you understand what you are doing. Then, report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGB0Jhk3FKuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset need to be reshaped to make it suitable for feedforword model\n",
        "def preprocess_for_ff(x_train, y_train, x_val, y_val):\n",
        "    x_train_ff = x_train.reshape((-1, 5*5*3))\n",
        "    y_train_ff = y_train.reshape((-1, 1))\n",
        "    x_val_ff = x_val.reshape((-1, 5*5*3))\n",
        "    y_val_ff = y_val.reshape((-1, 1))\n",
        "    x_scaler = normalizer_std(x_train_ff)\n",
        "    x_train_ff = x_scaler.transform(x_train_ff)\n",
        "    x_val_ff = x_scaler.transform(x_val_ff)\n",
        "    return x_train_ff, y_train_ff, x_val_ff, y_val_ff\n",
        "\n",
        "x_train_ff, y_train_ff, x_val_ff, y_val_ff = preprocess_for_ff(x_train, y_train, x_val, y_val)\n",
        "print(x_train_ff.shape, y_train_ff.shape)\n",
        "print(x_val_ff.shape, y_val_ff.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p77LrAbilkK7",
        "colab_type": "text"
      },
      "source": [
        "Explain each line of code in the function preprocess_for_ff()\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddS--sUaFKu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def get_feedforward_nn():    \n",
        "    input1 = Input(shape=(75,))    \n",
        "    x = Dense(200, activation='relu')(input1)    \n",
        "    x = Dense(200, activation='relu')(x)\n",
        "    x = Dense(200, activation='relu')(x)\n",
        "    out = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=input1, outputs=out)\n",
        "    model.compile(optimizer=Adam(0.01),\n",
        "                loss='mse',\n",
        "                metrics=['mse'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz8m8ijkmUdU",
        "colab_type": "text"
      },
      "source": [
        "What is the activation function in the final dense layer? and why?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "Why is the loss MSE?\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-merQMZ3FKu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "K.clear_session()\n",
        "\n",
        "model_ff = get_feedforward_nn()\n",
        "# .summary provies an overview of the model\n",
        "model_ff.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfnyZsPlmJW7",
        "colab_type": "text"
      },
      "source": [
        "Explain why dense_1 has 15200 parameters\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRe8Rvt-FKu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "\n",
        "print('start training ff')\n",
        "\n",
        "# Path to save model parameters\n",
        "weight_path_model_ff ='model_ff_nn.h5'\n",
        "# Path to write tensorboard\n",
        "tensorboard_path_model_ff = 'Graphs/ff_nn'\n",
        "\n",
        "callbacks_list_model_ff_nn = [\n",
        "    TensorBoard(log_dir=tensorboard_path_model_ff, histogram_freq=1, write_graph=True, write_grads=True),\n",
        "    ModelCheckpoint(\n",
        "            weight_path_model_ff,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        ),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "]\n",
        "\n",
        "verbose = 1\n",
        "epochs, batch_size = [10,1024]\n",
        "\n",
        "history_ff = model_ff.fit(x_train_ff, y_train_ff, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                callbacks=callbacks_list_model_ff_nn, validation_data=(x_val_ff, y_val_ff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K4fRDrLmsVI",
        "colab_type": "text"
      },
      "source": [
        "history_ff tracks many useful information. Checkout what is included by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR8tDONfmzvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history_ff.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeXGk-wHm9Nj",
        "colab_type": "text"
      },
      "source": [
        "We can track many of the parameters using the history. Plot loss, mean_squared_error, val_mean_squared_error, and val_loss as a function of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSfIZE2W2Atr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO#1 ##\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPpjHMTNogW1",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>PARTIAL SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "train_loss = history_ff.history['loss']\n",
        "train_mse = history_ff.history['mean_squared_error']\n",
        "val_loss = history_ff.history['val_loss']\n",
        "val_mse = history_ff.history['val_mean_squared_error']\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.title('train loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXmuk1a2nRSA",
        "colab_type": "text"
      },
      "source": [
        "When does the model start to overfit?\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXQgJYrTne0o",
        "colab_type": "text"
      },
      "source": [
        "Plot the learning rate as a function of the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ZdGDjJnka7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO#2 ##\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKjTiHm4o4ba",
        "colab_type": "text"
      },
      "source": [
        "What makes the learning rate change?\n",
        "(hint: look at the callback [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau))\n",
        "\n",
        "\n",
        "**Ans:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymW77BubFKvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#3:                                                                      #\n",
        "# Write a function to evaluate your model. Your function must make prediction  #\n",
        "# using the input model and return mean square error of the model.             #\n",
        "#                                                                              #\n",
        "# Hint: https://keras.io/models/model#evaluate                                 #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "def evaluate(features, labels, model):\n",
        "    \"\"\"\n",
        "    Evaluate model on validation data\n",
        "    \"\"\"\n",
        "    # write code here (one line)\n",
        "    \n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7t7ks7vFKvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use majority rule as a baseline.\n",
        "def majority_baseline(label_set):\n",
        "    unique, counts = np.unique(label_set, return_counts=True)\n",
        "    majority = unique[np.argmax(counts)]\n",
        "    baseline = 0\n",
        "    label_set = label_set.reshape(-1,1)\n",
        "    for r in label_set:\n",
        "        baseline += (majority - r) ** 2 / len(label_set)\n",
        "    return baseline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_QU7h4lFKvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('baseline')\n",
        "print('train', majority_baseline(y_train))\n",
        "print('validate', majority_baseline(y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUvyWwLeceIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('FF-model')\n",
        "print('train', evaluate(x_train_ff, y_train_ff, model_ff))\n",
        "print('validate', evaluate(x_val_ff, y_val_ff, model_ff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JguJELuFKvL",
        "colab_type": "text"
      },
      "source": [
        "# (Optional) Tensorboard #\n",
        "The code provided also have Tensorboard (a visualization tool that comes with Tensorflow). Note the part that calls it `TensorBoard(log_dir='./Graph/' + graph_name, histogram_freq=1, write_graph=True, write_grads=True)`. This tells Tensorflow to write extra outputs to the `log_dir` which can then be used for visualization.\n",
        "\n",
        "To use Tensorboard follow the guide [here](https://medium.com/@tommytao_54597/use-tensorboard-in-google-colab-16b4bb9812a6)\n",
        "\n",
        "In Tensorboard, you will be able to debug your computation graph which can be hard to keep track in code. This is might seem trivial in Keras, but it is very helpful for Tensorflow. You can see a visualization of the computation graph at the `GRAPH` tab. If you see multiple dense layers (more than 4), this is caused by running the code several times without deleting the log dir. Delete the log dir and re-run the code.\n",
        "\n",
        "Next, let's look at the scalars tab, we can see the loss and accuracy on the training and validation set as they change over each epoch. This can be useful to detect overfitting.\n",
        "\n",
        "Another useful tab is the histograms tab. This plot histograms of the weights, biases, and outputs of each layer. The depth of the histograms show the change over epochs. We can see how the histograms of weights change over the training peroid. This can be used to debug vanishing gradients or getting stuck in local minimas.\n",
        "\n",
        "There are other useful tabs in Tensorboard, you can read about them in the Keras [documentation](https://keras.io/callbacks/#tensorboard) for tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww980aW6GY_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Graphs/ff_nn is a path of tensorboard_path_model_ff\n",
        "%tensorboard --logdir Graphs/ff_nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TUMxeJvFKvM",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard observation #\n",
        "\n",
        "**Optional TODO#1** Write your own interpretation of the logs from this example. A simple sentence or two for each tab is sufficient.\n",
        "\n",
        "**Your answer:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Ynr3VgFKvN",
        "colab_type": "text"
      },
      "source": [
        "# Dropout #\n",
        "\n",
        "You might notice that the 3-layered feedforward does not use dropout at all. Now, try adding dropout (dropout rate of 20%) to the model, run, and report the result again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oGy_DDvX5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this code just in case to clear the session of tensorflow\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbnMbqT7FKvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#4:                                                                      #\n",
        "# Write a function that return feedforward model with dropout                  #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "from tensorflow.keras.layers import Dropout\n",
        "def get_fully_connected_with_dropout():\n",
        "    #enter code below\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f64eu3E0FKvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ff_dropout = get_fully_connected_with_dropout()\n",
        "model_ff_dropout.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJHG3fvMFKvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#5:                                                                      #\n",
        "# Complete the code to train your dropout model                                #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "print('start training ff dropout')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flM71KL-q9wI",
        "colab_type": "text"
      },
      "source": [
        "Plot the losses and MSE of the training and validation as before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAIRXOxTEcox",
        "colab": {}
      },
      "source": [
        "history_ff_drop.history.keys()\n",
        "train_loss_drop = history_ff_drop.history['loss']\n",
        "train_mse_drop = history_ff_drop.history['mean_squared_error']\n",
        "val_loss_drop = history_ff_drop.history['val_loss']\n",
        "val_mse_drop = history_ff_drop.history['val_mean_squared_error']\n",
        "\n",
        "plt.plot(train_loss_drop)\n",
        "plt.title('train loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "plt.plot(val_loss_drop)\n",
        "plt.title('validation loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDeWFRrxFKvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#6:                                                                      #\n",
        "# Complete the code to evaluate your dropout model                             #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "def evaluate_dropout(features, labels, model):\n",
        "    \"\"\"\n",
        "    Evaluate model on validation data\n",
        "    \"\"\"\n",
        "    ## enter code below\n",
        "    \n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJcKIDEon2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('FF-dropout-model')\n",
        "print('train', evaluate(x_train_ff, y_train_ff, model_ff_dropout))\n",
        "print('validate', evaluate(x_val_ff, y_val_ff, model_ff_dropout))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJFdUpD8FKvc",
        "colab_type": "text"
      },
      "source": [
        "# Convolution Neural Networks\n",
        "Now, you are going to implement you own 2d-convolution neural networks with the following structure.\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param\n",
        "=================================================================\n",
        "input_1 (InputLayer)         (None, 5, 5, 3)           0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 3, 3, 200)         5600      \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 1800)              0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 200)               360200    \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 200)               40200     \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 1)                 201       \n",
        "=================================================================\n",
        "Total params: 406,201\n",
        "Trainable params: 406,201\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```\n",
        "These parameters are simple guidelines to save your time.    \n",
        "You can play with them in the final section which you can choose any normalization methods, activation function, as well as any hyperparameter the way you want.         \n",
        "\n",
        "Hint: You should read keras documentation to see the list of available layers and options you can use.                         "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzH0DiH_XzOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6vLD-bdFKvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#7:                                                                     #\n",
        "# Complete the code for preparing data for training CNN                        #\n",
        "# Input for CNN should not have time step.                                     #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten\n",
        "def preprocess_for_cnn(x_train, y_train, x_val, y_val):\n",
        "    # Enter code below\n",
        "\n",
        "    return x_train_cnn,y_train_cnn,x_val_cnn,y_val_cnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1kmlOtfFKvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#8:                                                                     #\n",
        "# Write a function that returns keras convolution nueral network model.        #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "def get_conv2d_nn():\n",
        "    # Enter code below\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-bDQL3FFKvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#9:                                                                     #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "#                                                                              #\n",
        "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
        "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
        "# process. Feel free to use any other callback function available.             #\n",
        "################################################################################\n",
        "\n",
        "print('start training conv2d')\n",
        "model_cnn = get_conv2d_nn()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6FcmyjxLPrxG",
        "colab": {}
      },
      "source": [
        "history_cnn.history.keys()\n",
        "train_loss_cnn = history_cnn.history['loss']\n",
        "train_mse_cnn = history_cnn.history['mean_squared_error']\n",
        "val_loss_cnn = history_cnn.history['val_loss']\n",
        "val_mse_cnn = history_cnn.history['val_mean_squared_error']\n",
        "\n",
        "plt.plot(train_loss_cnn)\n",
        "plt.title('train loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "plt.plot(val_loss_cnn)\n",
        "plt.title('validation loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbt8pJIQFKvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('CNN-model')\n",
        "print('train', evaluate(x_train_cnn, y_train_cnn, model_cnn))\n",
        "print('validate', evaluate(x_val_cnn, y_val_cnn, model_cnn))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEARLiH0FKvo",
        "colab_type": "text"
      },
      "source": [
        "# Gated Recurrent Units\n",
        "\n",
        "Now, you are going to implement you own GRU network with the following structure.\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input_1 (InputLayer)         (None, 5, 75)             0         \n",
        "_________________________________________________________________\n",
        "gru_1 (GRU)                  (None, 5, 200)            165600    \n",
        "_________________________________________________________________\n",
        "time_distributed_1 (TimeDist (None, 5, 200)            40200     \n",
        "_________________________________________________________________\n",
        "time_distributed_2 (TimeDist (None, 5, 1)              201       \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 5)                 0         \n",
        "=================================================================\n",
        "Total params: 206,001\n",
        "Trainable params: 206,001\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```\n",
        "\n",
        "\n",
        "These parameters are simple guidelines to save your time.    \n",
        "You can play with them in the final section which you can choose any normalization methods, activation function, as well as any hyperparameter the way you want.         \n",
        "The result should be better than the feedforward model and at least on par with your CNN model.    \n",
        "\n",
        "Do consult keras documentation on how to use [GRUs](https://keras.io/layers/recurrent/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbkrNFIQX0ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q53iJttkFKvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#10:                                                                     #\n",
        "# Complete the code for preparing data for training GRU                        #\n",
        "# GRU's input should has 3 dimensions.                                         #\n",
        "# The dimensions should compose of entries, time-step, and features.          #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "from tensorflow.keras.layers import GRU,TimeDistributed\n",
        "\n",
        "def preprocess_for_gru(x_train, y_train, x_val, y_val):\n",
        "    # Enter code below\n",
        "    \n",
        "    return x_train_gru, y_train_gru, x_val_gru, y_val_gru"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk6hF98mFKvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#11                                                                      #\n",
        "# Write a function that returns keras GRU network model.                       #\n",
        "# Your goal is to predict a precipitation of every time step.                  #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "def get_gru():\n",
        "    # Enter code below\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f02waLbMFKvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#12                                                                      #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "#                                                                              #\n",
        "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
        "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
        "# process. Feel free to use any other callback function available.             #\n",
        "################################################################################\n",
        "print('start training gru')\n",
        "model_gru = get_gru()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W2HzoOqpP2Tc",
        "colab": {}
      },
      "source": [
        "history_gru.history.keys()\n",
        "train_loss_gru = history_gru.history['loss']\n",
        "train_mse_gru = history_gru.history['mean_squared_error']\n",
        "val_loss_gru = history_gru.history['val_loss']\n",
        "val_mse_gru = history_gru.history['val_mean_squared_error']\n",
        "\n",
        "plt.plot(train_loss_gru)\n",
        "plt.title('train loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "plt.plot(val_loss_gru)\n",
        "plt.title('validation loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Zbc4mIFKv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('GRU-model')\n",
        "print('train', evaluate(x_train_gru, y_train_gru, model_gru))\n",
        "print('validate', evaluate(x_val_gru, y_val_gru, model_gru))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkoGHlI8FKv5",
        "colab_type": "text"
      },
      "source": [
        "# Final Section\n",
        "# Keras playground\n",
        "\n",
        "Now, train the best model you can do for this task. You can use any model structure and function available.    \n",
        "Remember that trainig time increases with the complexity of the model. You might find TensorBoard helpful in tuning of complicated models.    \n",
        "Your model should be better than your CNN or GRU model in the previous sections.\n",
        "\n",
        "Some ideas:\n",
        "\n",
        "- Tune the hyperparameters\n",
        "- Adding dropouts\n",
        "- Combining CNN with GRUs\n",
        "\n",
        "You should tune your model on training and validation set.    \n",
        "**The test set should be used only for the last evaluation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIe5IeuFaVat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hibvTeKFKv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#13                                                                       #\n",
        "# Write a function that returns keras your best model. You can use anything    #\n",
        "# you want. The goal here is to create the best model you can think of.        #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "def get_my_best_model():\n",
        "    pass\n",
        "    return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfNpynXlFKv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# TODO#14                                                                       #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "#                                                                              #\n",
        "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
        "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
        "# process. Feel free to use any other callback function available.             #\n",
        "################################################################################\n",
        "print('start training the best model')\n",
        "my_best_model = get_my_best_model()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOVQ2zHkFKv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluate(x_val_best, y_val_best, model)\n",
        "#evaluate(x_test_best, y_test_best, model)\n",
        "#Also evaluate your fully-connected model and CNN/GRU model on the test set."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHyzJulTFKwA",
        "colab_type": "text"
      },
      "source": [
        "To get full credit for this part, your best model should be better than the previous models on the **test set**. \n",
        "\n",
        "\n",
        "Explain what helped and what did not help here\n",
        "\n",
        "**Ans:**"
      ]
    }
  ]
}